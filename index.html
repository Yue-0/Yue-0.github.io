<!-- author: YueLin -->

<html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="styles/icon.css">
        <link rel="stylesheet" href="styles/item.css">
        <link rel="stylesheet" href="styles/image.css">
        <link rel="stylesheet" href="styles/label.css">
        <link rel="stylesheet" href="styles/photo.css">
        <link rel="stylesheet" href="styles/overall.css">
        <title>Yue Lin</title>
    </head>

    <body>
        <header>
            <div>
                <img id="photo" src="images/photos/2024.jpg">
                <div class="photos" id="photos">
            </div>
            <h1 id="name">Yue Lin</h1>
            
            <div class="icons">
                <!-- <a href="CV.pdf" class="icon" target="_blank">
                    <img id="cv" src="images/icons/light/cv.svg">
                </a> -->

                <a href="https://github.com/Yue-0" class="icon" target="_blank">
                    <img id="github" src="images/icons/light/github.svg">
                </a>

                <div class="translate" onclick="translation()">
                    <img id="translate" src="images/icons/light/translate.svg">
                </div>
                
                <!-- <div class="icon">
                    <img id="light" src="images/icons/light/light.svg">
                </div> -->
            </div>
        
        </header>

        <div class="container">

            <div class="profile" id="profile">
                Hi, I'm Yue Lin, this website is a brief introduction about me.<br>
                I received my Bachelor of Engineering degree from Dalian University of Technology in 2023, and was recommended for a Master's degree. <br>
                Currently, I'm a graduate student at IIAU Lab of Dalian University of Technology, under the guidance of Professor Huchuan Lu, and my research direction is autonomous motion planning and visual tracking of robots.
            </div>

            <div>
                <h2>
                    <div class="section" id="papers"> Papers </div> 
                    <div class="show" onclick="callback(this)">
                        <div class="arrow"></div>
                    </div>
                </h2>

                <div class="paper" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="iros24title">
                            Safety-First Tracker: A Trajectory Planning Framework for Omnidirectional Robot Tracking
                        </div>
                        <div class="level" id="iros24">
                            IROS 2024
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="iros24authors">
                            <b>Yue Lin</b>, Yang Liu, Pingping Zhang, Xin Chen, Dong Wang, Huchuan Lu
                        </div>
                        <a href="https://ieeexplore.ieee.org/abstract/document/10802592" id="iros24paper" target="_blank"> Paper </a> |
                        <a href="https://github.com/user-attachments/assets/a8feecc0-e678-453f-9f09-61cce6f2eb47" id="iros24video" target="_blank"> Video </a> |
                        <a href="https://github.com/Yue-0/SF-Tracker" id="iros24code" target="_blank"> Code </a><br>
                        <div id="iros24details">
                            We propose a two-stage trajectory planning framework that prioritizes the robot's trajectory safety and then plans the robot's orientation to ensure target visibility. Our method enables the robot to safely follow a target in complex dynamic environments.
                        </div>
                    </div>
                </div>

                <div class="paper" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="ral25title">
                            Eva-Tracker: An ESDF-update-free Approach for Aerial Tracking with Visibility-aware Planning
                        </div>
                        <div class="level" id="ral25">
                            RA-L Submission
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="ral25authors">
                            <b>Yue Lin</b>, Zihao Huang, Yang Liu, Dong Wang, Huchuan Lu
                        </div>
                        <!-- <a href="" id="ral25paper" target="_blank"> Paper </a> | -->
                        <!-- <a href="" id="ral25video" target="_blank"> Video </a> | -->
                        <span id="ral25paper"> Paper </span> |
                        <span id="ral25video"> Video </span> |
                        <a href="https://github.com/Yue-0/Eva-Tracker" id="ral25code" target="_blank"> Code </a><br>
                        <div id="ral25details">
                            We designed a target tracking method for quadrotors without building environmental ESDF or safe flight corridors. We propose the pre-built FOV-ESDF to optimize target visibility, allowing the drone to stably track the target in complex environments and avoid collision and target occlusion.
                        </div>
                    </div>
                </div>

                <div class="paper" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="iros25title">
                            GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric
                        </div>
                        <div class="level" id="iros25">
                            IROS 2025 Submission
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="iros25authors">
                            <b>Yue Lin</b>, Xiaoxuan Zhang, Yang Liu, Dong Wang, Huchuan Lu
                        </div>
                        <!-- <a href="" id="iros25paper" target="_blank"> Paper </a> | -->
                        <!-- <a href="" id="iros25video" target="_blank"> Video </a> | -->
                        <!-- <a href="" id="iros25code" target="_blank"> Code </a> -->
                        <span id="iros25paper"> Paper </span> |
                        <span id="iros25video"> Video </span> |
                        <span id="iros25code"> Code </span>
                        <div id="iros25details">
                            We propose a perception-aware trajectory planning framework with geometric feature metrics to improve the localization accuracy of autonomous robots. This method improves the LiDAR localization accuracy during navigation by enabling the robot to actively avoid areas that cause high localization errors.
                        </div>
                    </div>
                </div>
            </div>

            <div>
                <h2>
                    <div class="section" id="projects"> Projects </div> 
                    <div class="show" onclick="callback(this)">
                        <div class="arrow"></div>
                    </div>
                </h2>

                <div class="project" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="nsfc_title">
                            Learning Active Perception and Adversarial Game Modeling of Single-agent
                        </div>
                        <div class="level" id="nsfc">
                            NSFC Major Project
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="nsfc_authors">
                            <b>Yue Lin</b>, Peng Zhang, Hangyou Yu, Yang Liu, Dong Wang, Huchuan Lu
                        </div>
                        <a href="https://github.com/Yue-0/RMUA" id="nsfc_code" target="_blank"> Code </a><br>
                        <div id="nsfc_details">
                            We use the RoboMaster2020 standard AI robot to conduct 1v1 fully automatic confrontation games. The robot can actively perceive the environment and enemy target, and establish intelligent strategies to automatically conduct confrontation games.
                        </div>
                    </div>
                </div>

                <div class="project" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="tsinghua_title">
                            Methods and Applications of Multi-agent Confrontation Games in Open Environments
                        </div>
                        <div class="level" id="tsinghua">
                            Tsinghua University Exchange & NSFC Major Project
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="tsinghua_authors">
                            Di Wu, Zijie Zhao, <b>Yue Lin</b>, Wenhao Zhou, Huchuan Lu, You He
                        </div>
                        <span id="tsinghua_video"> Video </span>
                        <div id="tsinghua_details">
                            We developed multi-robot collaborative capture algorithms in open environments, including environmental perception, target recognition, motion planning, and strategy learning, so that the robot swarm can quickly and accurately capture an intelligent escaping target in unknown environments.
                        </div>
                    </div>
                </div>

                <div class="project" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title" id="201title">
                            Research on Lightweight Object Tracking Method Based on Transformers
                        </div>
                        <div class="level" id="201">
                            201 Institute Cooperation Project
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="201authors">
                            <b>Yue Lin</b>, Ziqi guan, Ben Kang, Xin Chen, Dong Wang, Huchuan Lu
                        </div>
                        <a href="images/images/201.gif" id="201video"> Video </a> |
                        <a href="https://github.com/Yue-0/VisualTracking-NX" id="201code" target="_blank"> Code </a><br>
                        <div id="201details">
                            We developed a high-precision, lightweight single object tracking model based on Transformer for the 201 Institute. The model shows robust performance for small targets and frequently occluded targets, and can run in real time at 110 FPS on edge devices such as JetSon Orin NX.
                        </div>
                    </div>
                </div>
            </div>

            <div>
                <h2>
                    <div class="section" id="competitions"> Competition </div>  
                    <div class="show" onclick="callback(this)">
                        <div class="arrow"></div>
                    </div>
                </h2>

                <div class="competition" onclick="display(event, this)">
                    <div class="introduction">
                        <div class="title">
                            ICRA 2022 Sim2Real Challenge
                        </div>
                        <div class="level" id="icra22">
                            4th in the World
                        </div>
                    </div>
                    <div class="details">
                        <div class="authors" id="icra22authors">
                            Shiyao Li, <b>Yue Lin</b>, Zuyao You, Jiansong Pei, Zeyun Wang, Feilong Wang
                        </div>
                        <a href="images/images/icra22.gif" id="icra22video"> Video </a> |
                        <a href="https://air.tsinghua.edu.cn/info/1007/1679.htm" id="icra22web" target="_blank"> Website </a><br>
                        <div id="icra22details">
                            We developed lightweight visual recognition and navigation algorithms in a simulation environment, which enabled the robot to autonomously search and grab the corresponding ores, and transport them to the designated location through autonomously navigation. The algorithms developed in the simulation environment can be directly deployed on the real robot.
                        </div>
                    </div>
                </div>
            </div>

        </div>

        <div class="overlay" id="overlay">
            <img id="gif" class="gif" src="">
        </div>

        <footer>
            <p>&copy; 2025 Yue Lin. All Rights Reserved.</p>
            <p>Email: <a href="mailto:yuelin@mail.dlut.edu.cn" class="link">yuelin@mail.dlut.edu.cn</a></p>
        </footer>

        <script src="scripts/image.js"></script>
        <script src="scripts/photo.js"></script>
        <script src="scripts/callback.js"></script>
        <script src="scripts/language.js"></script>
    </body>
</html>
